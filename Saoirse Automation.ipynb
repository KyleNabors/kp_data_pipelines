{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af061f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe52126",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%d_%m_%Y\")\n",
    "print(current_date)\n",
    "\n",
    "folder_name = f\"dashboard_files_{current_date}\"\n",
    "folder_path = os.path.join(r\"C:\\Users\\O304312\\Documents\\Dashboard Files\", folder_name)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    print(f\"Folder created at: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Folder already exists: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61eecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reports run on a two month lag (1 month then we wait till the 11th for the DOR reports.) So we are setting our file naming and data extraction accordingly.\"\"\"\n",
    "\n",
    "today = datetime.today()\n",
    "first_of_this_month = today.replace(day=1)\n",
    "first_of_last_month = (first_of_this_month - pd.DateOffset(months=1)).replace(day=1)\n",
    "\n",
    "month = first_of_last_month.strftime(\"%B\").lower()\n",
    "print(month)\n",
    "cap_month = month.capitalize()\n",
    "print(cap_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_ds = r\"J:\\ONELINK\\Snapshot Datasources\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e65149",
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_data = pd.read_csv(\n",
    "    r\"C:\\Users\\O304312\\Downloads\\Data Table Visit Data.csv\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "print(visit_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cba119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Aligning to current Tableau Dashboard Naming Conventions. Real fix is to change it to reflect Viewpoint report changes\"\"\"\n",
    "\n",
    "visit_data = visit_data[\n",
    "    [\n",
    "        \"Site Name\",\n",
    "        \"Site Study Code\",\n",
    "        \"Subject ID\",\n",
    "        \"Participant Status\",\n",
    "        \"Participant Protocol Arm\",\n",
    "        \"Visit Period\",\n",
    "        \"Visit Name\",\n",
    "        \"Visit Status\",\n",
    "        \"Visit Completed Date\",\n",
    "    ]\n",
    "]\n",
    "print(visit_data.dtypes)\n",
    "\n",
    "visit_data = visit_data.rename(\n",
    "    columns={\n",
    "        \"Site Name\": \"Site\",\n",
    "        \"Site Study Code\": \"Site Study ID\",\n",
    "        \"Participant Protocol Arm\": \"Arm\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Convert Visit Completed Date to datetime\n",
    "visit_data[\"Visit Completed Date\"] = pd.to_datetime(\n",
    "    visit_data[\"Visit Completed Date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "visit_data = visit_data[visit_data[\"Visit Completed Date\"] < first_of_last_month]\n",
    "\n",
    "visit_data.to_csv(f\"{folder_path}/Visit Data_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2505a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_accruals = pd.read_csv(\n",
    "    r\"C:\\Users\\O304312\\Downloads\\Data Table Study Accrual.csv\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "print(study_accruals.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2aea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "study_accruals = study_accruals[\n",
    "    [\n",
    "        \"Site Name\",\n",
    "        \"Sponsor Site Number\",\n",
    "        \"Network Study Code\",\n",
    "        \"Network Study Status\",\n",
    "        \"Site Study Code\",\n",
    "        \"Site Study Status\",\n",
    "        \"Study Title\",\n",
    "        \"Study Phase\",\n",
    "        \"Study Type\",\n",
    "        \"Funding Source\",\n",
    "        \"Site IRB Name\",\n",
    "        \"Site IRB Status\",\n",
    "        \"Site IRB Expiration Date\",\n",
    "        \"IRB Submission Number\",\n",
    "        \"Principal Investigators\",\n",
    "        \"Lead Coordinators\",\n",
    "        \"Site Study Start Date\",\n",
    "        \"Site Study End Date\",\n",
    "        \"Site Enrollment Start Date\",\n",
    "        \"Site Enrollment End Date\",\n",
    "        \"Study Therapeutic Areas\",\n",
    "        \"Study Therapeutic Area Details\",\n",
    "        \"Study Sponsors\",\n",
    "        \"Site Enrollment Target\",\n",
    "        \"CRO Name\",\n",
    "        \"Total Patients Prescreened Sum\",\n",
    "        \"Failed Prescreening Sum\",\n",
    "        \"Total Participants Sum\",\n",
    "        \"In Screening Sum\",\n",
    "        \"Failed Screening Sum\",\n",
    "        \"In Treatment Sum\",\n",
    "        \"Completed Sum\",\n",
    "        \"Follow Up Sum\",\n",
    "        \"Off Study Sum\",\n",
    "        \"Long Term Follow Up Sum\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "study_accruals = study_accruals.rename(\n",
    "    columns={\n",
    "        \"Site Name\": \"Site\",\n",
    "        \"Site Study Code\": \"Site Study ID\",\n",
    "        \"Site Enrollment Target\": \"Site Enrollment Targets\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(study_accruals.dtypes)\n",
    "\n",
    "study_accruals.to_csv(f\"{folder_path}/Study Accrual Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a21859",
   "metadata": {},
   "outputs": [],
   "source": [
    "partis_info = pd.read_csv(\n",
    "    r\"C:\\Users\\O304312\\Downloads\\Data Table Participant Information.csv\",\n",
    "    low_memory=False,\n",
    ")\n",
    "\n",
    "print(partis_info.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac552fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "partis_info = partis_info[\n",
    "    [\n",
    "        \"Subject ID\",\n",
    "        \"Site Study Code\",\n",
    "        \"Participant Status\",\n",
    "        \"Participant Status Date\",\n",
    "        \"Participant Latest Consent Date\",\n",
    "        \"Participant Consent Status\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "partis_info[\"Participant Latest Consent Date\"] = partis_info[\n",
    "    \"Participant Latest Consent Date\"\n",
    "].replace([\"\", \"0\", 0], pd.NA)\n",
    "if \"Latest Screen Failure Date\" in partis_info.columns:\n",
    "    partis_info[\"Participant Latest Consent Date\"] = partis_info[\n",
    "        \"Participant Latest Consent Date\"\n",
    "    ].fillna(partis_info[\"Latest Screen Failure Date\"])\n",
    "\n",
    "\n",
    "partis_info = partis_info.rename(\n",
    "    columns={\n",
    "        \"Site Study Code\": \"Site Study ID\",\n",
    "        \"Participant Status Date\": \"Current Status Date\",\n",
    "        \"Participant Latest Consent Date\": \"Consent Date\",\n",
    "        \"Participant Consent Status\": \"Consent Result\",\n",
    "    }\n",
    ")\n",
    "\n",
    "partis_info[\"Consent Date\"] = pd.to_datetime(\n",
    "    partis_info[\"Consent Date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "partis_info = partis_info[partis_info[\"Consent Date\"] < first_of_last_month]\n",
    "\n",
    "partis_info.to_csv(\n",
    "    f\"{folder_path}/Participant Information Data Sheet.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7137981",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv(\n",
    "    r\"C:\\Users\\O304312\\Downloads\\Transaction.csv\", low_memory=False\n",
    ")\n",
    "\n",
    "transactions = transactions.drop(columns=[\"Unnamed: 0\"])\n",
    "print(transactions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359152e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[\"Accountable Completed Date\"] = pd.to_datetime(\n",
    "    transactions[\"Accountable Completed Date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "transactions[\"Accountable Completed Date\"] = transactions[\n",
    "    \"Accountable Completed Date\"\n",
    "].replace([\"\", \"0\", 0], pd.NA)\n",
    "\n",
    "transactions = transactions[\n",
    "    (transactions[\"Accountable Completed Date\"] < first_of_last_month)\n",
    "    | (transactions[\"Accountable Completed Date\"].isnull())\n",
    "]\n",
    "\n",
    "mask = transactions[\"Accountable Completed Date\"].isna()\n",
    "transactions.loc[mask, \"Accountable Completed Date\"] = pd.to_datetime(\n",
    "    transactions.loc[mask, \"Transaction Created Date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "num_blank_rows = transactions[\"Accountable Completed Date\"].isna().sum()\n",
    "print(f\"Number of blank rows in 'Accountable Completed Date': {num_blank_rows}\")\n",
    "\n",
    "transactions = transactions.drop(columns=[\"Transaction Created Date\"])\n",
    "\n",
    "transactions[\"Account Code\"] = transactions[\"Account Code\"].replace([\"\", \"0\", 0], pd.NA)\n",
    "\n",
    "transactions[\"Account Code\"] = transactions[\"Account Code\"].fillna(47205)\n",
    "\n",
    "transactions.loc[\n",
    "    transactions[\"Transaction Line Item\"] == \"StudyActivity\", \"Account Code\"\n",
    "] = 47206"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "excel_files = glob.glob(\n",
    "    r\"J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\zzz_CTP Projects List\\DOR Finance CTP List\\CTP Project List Reconciled *.xlsx\"\n",
    ")\n",
    "\n",
    "\n",
    "def extract_date(filename):\n",
    "    match = re.search(r\"(\\d{6})\\.xlsx$\", filename)\n",
    "    return match.group(1) if match else \"\"\n",
    "\n",
    "\n",
    "excel_files_sorted = sorted(excel_files, key=extract_date, reverse=True)\n",
    "\n",
    "if excel_files_sorted:\n",
    "    latest_excel = excel_files_sorted[0]\n",
    "    dor_ctp_projects = pd.read_excel(latest_excel)\n",
    "    print(f\"Loaded file: {latest_excel}\")\n",
    "else:\n",
    "    print(\"No matching Excel files found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3aacb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transactions.columns)\n",
    "print(dor_ctp_projects.columns)\n",
    "dor_ctp_projects = dor_ctp_projects[[\"ProjectID\", \"IDC Rate\"]]\n",
    "\n",
    "dor_ctp_projects = dor_ctp_projects.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec0061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adding in OH rate based on what the overhead rate was at the time the study was created\"\"\"\n",
    "\n",
    "transactions = pd.merge(\n",
    "    transactions,\n",
    "    dor_ctp_projects,\n",
    "    left_on=\"Service Line Code\",\n",
    "    right_on=\"ProjectID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "transactions[\"Transaction Amount\"] = pd.to_numeric(\n",
    "    transactions[\"Transaction Amount\"], errors=\"coerce\"\n",
    ")\n",
    "transactions[\"IDC Rate\"] = pd.to_numeric(transactions[\"IDC Rate\"], errors=\"coerce\")\n",
    "\n",
    "mask = (transactions[\"Transaction Line Item\"] == \"AdHoc\") & (\n",
    "    transactions[\"Account Code\"] == 47205\n",
    ")\n",
    "transactions.loc[mask, \"Transaction Amount\"] = transactions.loc[\n",
    "    mask, \"Transaction Amount\"\n",
    "] * (1 + transactions.loc[mask, \"IDC Rate\"].fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66627c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id_list = pd.read_csv(\n",
    "    \"J:\\\\ONELINK//Snapshot Datasources//SignalPath ProjectID Lookup.csv\",\n",
    "    low_memory=False,\n",
    "    encoding=\"cp1252\",\n",
    ")\n",
    "print(project_id_list.columns)\n",
    "\n",
    "transactions = pd.merge(\n",
    "    transactions,\n",
    "    project_id_list,\n",
    "    left_on=\"Service Line Code\",\n",
    "    right_on=\"Project ID\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "print(transactions.columns)\n",
    "\n",
    "list_csv = pd.read_csv(\n",
    "    r\"J:\\ONELINK\\Snapshot Datasources\\04 2025 April\\_Transaction Data april 2025.csv\"\n",
    ")\n",
    "\n",
    "columns_list = list_csv.columns.tolist()\n",
    "\n",
    "print(columns_list)\n",
    "transactions[\"Transaction Created Date\"] = transactions[\"Accountable Completed Date\"]\n",
    "transactions = transactions.rename(\n",
    "    columns={\n",
    "        \"Transaction Amount\": \"Amount\",\n",
    "        \"Site Study ID\": \"Site Protocol Version Desc\",\n",
    "    }\n",
    ")\n",
    "\n",
    "transactions = transactions.loc[:, columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53bc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.to_csv(\n",
    "    f\"{folder_path}/_Transaction Data.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3ae0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Checking available datasources for RNG numbers for studies. Not efficient but requires data management and creation processes to be updated to fix\"\"\"\n",
    "\n",
    "studies = transactions[\n",
    "    [\n",
    "        \"Service Line Code\",\n",
    "        \"Site Study Code\",\n",
    "    ]\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571eb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a raw string to avoid invalid escape sequence warnings\n",
    "project_list = pd.read_excel(\n",
    "    r\"J:\\ONELINK\\Snapshot Datasources\\CTP Project List Reconciled.xlsx\"\n",
    ")\n",
    "\n",
    "project_list = project_list[[\"ProjectID\", \"Project Status\", \"Funding Type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bc6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "trac_id = pd.read_json(r\"J:\\TRAC\\TRAC_Data.json\", encoding=\"utf-16\")\n",
    "\n",
    "trac_id = pd.json_normalize(trac_id[\"TRAC_Data\"])\n",
    "\n",
    "lookup_table = trac_id[[\"ProjectID\", \"ReferenceNum\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cfae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "signalpath_lookup = pd.read_csv(\n",
    "    r\"J:\\ONELINK\\Snapshot Datasources\\SignalPath ProjectID Lookup.csv\",\n",
    "    low_memory=False,\n",
    "    encoding=\"cp1252\",\n",
    ")\n",
    "\n",
    "print(f\"Number of rows in signalpath_lookup: {len(signalpath_lookup)}\")\n",
    "\n",
    "\"\"\"Export a backup of the file in case update process goes off the rails\"\"\"\n",
    "\n",
    "signalpath_lookup.to_csv(f\"{folder_path}/SIGNALPATH LOOKUP BACKUP DO NOT COPY.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abb598",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "missing_site_study_codes = studies.loc[\n",
    "    ~studies[\"Site Study Code\"].isin(signalpath_lookup[\"Site Study ID\"])\n",
    "]\n",
    "\n",
    "mask_rng = (\n",
    "    missing_site_study_codes[\"Site Study Code\"].str.contains(r\"RNG\\d{6}\", regex=True, na=False)\n",
    "    & (missing_site_study_codes[\"Service Line Code\"].isna() | (missing_site_study_codes[\"Service Line Code\"] == \"\"))\n",
    ")\n",
    "missing_site_study_codes.loc[mask_rng, \"Service Line Code\"] = (\n",
    "    missing_site_study_codes.loc[mask_rng, \"Site Study Code\"].str.extract(r\"(RNG\\d{6})\", expand=False)\n",
    ")\n",
    "\n",
    "to_append = missing_site_study_codes[[\"Site Study Code\"]].rename(\n",
    "    columns={\"Site Study Code\": \"Site Study ID\"}\n",
    ")\n",
    "to_append[\"Project ID\"] = missing_site_study_codes[\"Service Line Code\"].values\n",
    "\n",
    "signalpath_lookup = pd.concat([signalpath_lookup, to_append], ignore_index = True)\n",
    "\n",
    "\n",
    "# Find duplicated Site Study IDs\n",
    "dup_mask = signalpath_lookup.duplicated(subset=[\"Site Study ID\"], keep=False)\n",
    "\n",
    "# For duplicates, keep the row where Project ID is 'Non-Industry'\n",
    "signalpath_lookup = signalpath_lookup.loc[\n",
    "    ~dup_mask | ((dup_mask) & (signalpath_lookup[\"Project ID\"] == \"Non-Industry\"))\n",
    "].drop_duplicates(subset=[\"Site Study ID\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67fab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, regular merge\n",
    "signalpath_lookup = signalpath_lookup.merge(\n",
    "    lookup_table, left_on=\"Site Study ID\", right_on=\"ReferenceNum\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Now, for rows where ReferenceNum is contained within Site Study ID but not an exact match\n",
    "mask_no_match = signalpath_lookup[\"ReferenceNum\"].isna()\n",
    "for idx, row in signalpath_lookup[mask_no_match].iterrows():\n",
    "    matches = lookup_table[\n",
    "        lookup_table[\"ReferenceNum\"].apply(\n",
    "            lambda x: x in row[\"Site Study ID\"] if pd.notna(x) else False\n",
    "        )\n",
    "    ]\n",
    "    if not matches.empty:\n",
    "        # Assign the first match (or you can handle multiple matches as needed)\n",
    "        signalpath_lookup.at[idx, \"ProjectID\"] = matches.iloc[0][\"ProjectID\"]\n",
    "        signalpath_lookup.at[idx, \"ReferenceNum\"] = matches.iloc[0][\"ReferenceNum\"]\n",
    "\n",
    "# Fill missing 'Project ID' with 'ProjectID' where 'Project ID' is blank or NA and 'ProjectID' is not\n",
    "mask_fill = (\n",
    "    signalpath_lookup[\"Project ID\"].isna() & signalpath_lookup[\"ProjectID\"].notna()\n",
    ")\n",
    "signalpath_lookup.loc[mask_fill, \"Project ID\"] = signalpath_lookup.loc[\n",
    "    mask_fill, \"ProjectID\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "signalpath_lookup = signalpath_lookup[[\"Site Study ID\", \"Project ID\"]]\n",
    "\n",
    "signalpath_lookup = signalpath_lookup.merge(\n",
    "    project_list, left_on=\"Project ID\", right_on=\"ProjectID\", how=\"left\"\n",
    ")\n",
    "\n",
    "signalpath_lookup = signalpath_lookup[\n",
    "    ~signalpath_lookup[\"Project Status\"].isin([\"C\", \"E\"])\n",
    "]\n",
    "signalpath_lookup.loc[\n",
    "    signalpath_lookup[\"Funding Type\"].isin([\"FEDERAL\", \"FOUNDATION\"]), \"Project ID\"\n",
    "] = \"Non-Industry\"\n",
    "\n",
    "signalpath_lookup = signalpath_lookup[[\"Site Study ID\", \"Project ID\"]]\n",
    "\n",
    "signalpath_lookup = signalpath_lookup.dropna(subset=[\"Project ID\"])\n",
    "signalpath_lookup = signalpath_lookup.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_lookup = pd.read_csv(\n",
    "    r\"J:\\ONELINK\\Snapshot Datasources\\SignalPath ProjectID Lookup.csv\",\n",
    "    low_memory=False,\n",
    "    encoding=\"cp1252\",\n",
    ")\n",
    "\n",
    "missing_ids = sp_lookup[\n",
    "    ~sp_lookup[\"Site Study ID\"].isin(signalpath_lookup[\"Site Study ID\"])\n",
    "]\n",
    "\n",
    "missing_ids = missing_ids[~missing_ids[\"Project ID\"].isin(sp_lookup[\"Project ID\"])]\n",
    "print(missing_ids)\n",
    "\n",
    "sp_lookup = pd.concat([sp_lookup, missing_ids], ignore_index=True)\n",
    "\n",
    "print(f\"Number of rows in new signalpath_lookup: {len(sp_lookup)}\")\n",
    "\n",
    "sp_lookup.to_csv(\n",
    "    f\"{folder_path}/SignalPath ProjectID Lookup.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
