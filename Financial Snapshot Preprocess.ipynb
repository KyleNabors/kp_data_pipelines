{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab7a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89660aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Monthly Operating Statements\\2025\\Cumulative Report - Operating Statements - 0925 - Hard Coded.xlsx\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base = Path(r\"J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Monthly Operating Statements\")\n",
    "\n",
    "year_dirs = [p for p in base.iterdir() if p.is_dir() and p.name.isdigit()]\n",
    "if not year_dirs:\n",
    "    raise FileNotFoundError(f\"No year folders found under {base!s}\")\n",
    "latest_year_dir = max(year_dirs, key=lambda p: int(p.name))\n",
    "\n",
    "pattern_files = list(\n",
    "    latest_year_dir.glob(\"Cumulative Report - Operating Statements - *.xlsx\")\n",
    ")\n",
    "xlsx_files = pattern_files or list(latest_year_dir.glob(\"*.xlsx\"))\n",
    "if not xlsx_files:\n",
    "    raise FileNotFoundError(f\"No .xlsx files found in {latest_year_dir!s}\")\n",
    "\n",
    "latest_report = max(xlsx_files, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "report_path = latest_report\n",
    "print(report_path)\n",
    "\n",
    "dor = pd.read_excel(report_path, sheet_name=\"Cumulative Report\", skiprows=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb623b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID                                            object\n",
      "Project Title                                         object\n",
      "Program Area                                          object\n",
      "Funder Type                                           object\n",
      "Principal Investigator (PI)                           object\n",
      "Award Term Start Date                         datetime64[ns]\n",
      "Project Status                                        object\n",
      "Total Cash Receipts                                  float64\n",
      "Total Personnel                                      float64\n",
      "Total Contractual/\\nOutside Services Costs           float64\n",
      "Total \\nNon-Personnel                                float64\n",
      "Total Cost                                           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# drop Unnamed: 0 only if it exists\n",
    "if \"Unnamed: 0\" in dor.columns:\n",
    "    dor = dor.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# desired columns (use canonical names)\n",
    "desired_cols = [\n",
    "    \"Project ID\",\n",
    "    \"Project Title\",\n",
    "    \"Program Area\",\n",
    "    \"Funder Type\",\n",
    "    \"Principal Investigator (PI)\",\n",
    "    \"Award Term Start Date\",\n",
    "    \"Project Status\",\n",
    "    \"Total Cash Receipts\",\n",
    "    \"Total Personnel\",\n",
    "    \"Total Contractual/ Outside Services Costs\",\n",
    "    \"Total Non-Personnel\",\n",
    "    \"Total Cost\",\n",
    "]\n",
    "\n",
    "# normalize helper to match columns ignoring whitespace/newlines/case\n",
    "normalize = lambda s: \"\".join(s.split()).lower() if isinstance(s, str) else s\n",
    "col_map = {normalize(c): c for c in dor.columns}\n",
    "\n",
    "# build selected column list from available columns (skip missing ones)\n",
    "selected = []\n",
    "missing = []\n",
    "for c in desired_cols:\n",
    "    key = normalize(c)\n",
    "    if key in col_map:\n",
    "        selected.append(col_map[key])\n",
    "    else:\n",
    "        missing.append(c)\n",
    "\n",
    "if missing:\n",
    "    print(\n",
    "        f\"Warning: these desired columns were not found and will be skipped: {missing}\"\n",
    "    )\n",
    "\n",
    "# subset dataframe to the selected (available) columns\n",
    "dor = dor[selected]\n",
    "\n",
    "print(dor.dtypes)\n",
    "\n",
    "dor.to_excel(\n",
    "    \"C:\\\\Users\\\\O304312\\\\OneDrive - Kaiser Permanente\\\\Documents\\\\Tableau Dashboards\\\\New Financial Snapshot\\\\Data\\\\DOR Data Preprocessed.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7afa37c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Transaction Detail\\CTP Transaction Detail 103125.xlsx\n",
      "Columns: ['Project ID', 'NUID', 'Name', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025_Qtr1_Jan', '2025_Qtr1_Feb', '2025_Qtr1_Mar', '2025_Qtr2_Apr', '2025_Qtr2_May', '2025_Qtr2_Jun', '2025_Qtr3_Jul', '2025_Qtr3_Aug', '2025_Qtr3_Sep', '2025_Qtr4_Oct', '2025 Total', 'Grand Total']\n",
      "Loaded dataframe shape: (214, 26)\n"
     ]
    }
   ],
   "source": [
    "txn_base = Path(r\"J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Transaction Detail\")\n",
    "pattern = \"CTP Transaction Detail *.xlsx\"\n",
    "matches = list(txn_base.glob(pattern))\n",
    "\n",
    "if matches:\n",
    "    ctp_path = max(matches, key=lambda p: p.stat().st_mtime)\n",
    "else:\n",
    "\n",
    "    fallback = txn_base / \"CTP Transaction Detail 103125.xlsx\"\n",
    "    if fallback.exists():\n",
    "        ctp_path = fallback\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No files matching {pattern!s} and fallback {fallback!s} not found in {txn_base!s}\"\n",
    "        )\n",
    "\n",
    "print(\"Loading:\", ctp_path)\n",
    "\n",
    "ctp_hours = pd.read_excel(ctp_path, sheet_name=\"Hours\", header=[8, 9, 10, 11])\n",
    "\n",
    "\n",
    "def tidy(col):\n",
    "    parts = [\n",
    "        str(x).strip()\n",
    "        for x in col\n",
    "        if str(x).strip() not in {\"nan\", \"\"} and not str(x).startswith(\"Unnamed\")\n",
    "    ]\n",
    "    return \"_\".join(parts).strip(\"_\")\n",
    "\n",
    "\n",
    "ctp_hours.columns = [tidy(col) for col in ctp_hours.columns]\n",
    "\n",
    "ctp_hours = ctp_hours.rename(columns={\"Project\": \"Project ID\"})\n",
    "\n",
    "mask = ctp_hours[\"Project ID\"].astype(str).str.strip().str.lower().str.endswith(\"total\")\n",
    "ctp_hours = ctp_hours[mask].copy()\n",
    "ctp_hours.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rng_mask = (\n",
    "    ctp_hours[\"Project ID\"].astype(str).str.match(r\"^(RNG\\d+)\\s+Total$\", na=False)\n",
    ")\n",
    "ctp_hours.loc[rng_mask, \"Project ID\"] = (\n",
    "    ctp_hours.loc[rng_mask, \"Project ID\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"^(RNG\\d+)\\s+Total$\", r\"\\1\", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Columns:\", ctp_hours.columns.tolist())\n",
    "\n",
    "print(\"Loaded dataframe shape:\", ctp_hours.shape)\n",
    "\n",
    "ctp_hours.to_excel(\n",
    "    \"C:\\\\Users\\\\O304312\\\\OneDrive - Kaiser Permanente\\\\Documents\\\\Tableau Dashboards\\\\New Financial Snapshot\\\\Data\\\\DOR Personnel.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: J:\\VIEWPOINT\\SiteStudyDetails_Response\\2025-11-12-SiteStudyDetails.json\n",
      "Converted to DataFrame with shape: (1062, 40)\n"
     ]
    }
   ],
   "source": [
    "vp_folder = Path(\"J:\\\\VIEWPOINT\\\\SiteStudyDetails_Response\")\n",
    "\n",
    "pattern = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}-SiteStudyDetails\\.json$\")\n",
    "\n",
    "matches = [p for p in vp_folder.iterdir() if p.is_file() and pattern.match(p.name)]\n",
    "if not matches:\n",
    "    raise FileNotFoundError(f\"No SiteStudyDetails json files found in {vp_folder!s}\")\n",
    "\n",
    "latest_json = max(matches, key=lambda p: p.stat().st_mtime)\n",
    "print(\"Loading:\", latest_json)\n",
    "\n",
    "with latest_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    site_details = json.load(f)\n",
    "\n",
    "try:\n",
    "    ss_df = pd.json_normalize(site_details)\n",
    "    print(\"Converted to DataFrame with shape:\", ss_df.shape)\n",
    "except Exception:\n",
    "    ss_df = None\n",
    "    print(\"JSON loaded into 'site_details' (not converted to DataFrame).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fbc5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
