{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89660aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path(r\"J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Monthly Operating Statements\")\n",
    "\n",
    "year_dirs = [p for p in base.iterdir() if p.is_dir() and p.name.isdigit()]\n",
    "if not year_dirs:\n",
    "    raise FileNotFoundError(f\"No year folders found under {base!s}\")\n",
    "latest_year_dir = max(year_dirs, key=lambda p: int(p.name))\n",
    "\n",
    "pattern_files = list(\n",
    "    latest_year_dir.glob(\"Cumulative Report - Operating Statements - *.xlsx\")\n",
    ")\n",
    "xlsx_files = pattern_files or list(latest_year_dir.glob(\"*.xlsx\"))\n",
    "if not xlsx_files:\n",
    "    raise FileNotFoundError(f\"No .xlsx files found in {latest_year_dir!s}\")\n",
    "\n",
    "latest_report = max(xlsx_files, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "report_path = latest_report\n",
    "\n",
    "dor = pd.read_excel(report_path, sheet_name=\"Summary - DC only\", skiprows=6)\n",
    "dor = dor.rename(columns={'Short \"Project\" Title': \"DOR Project Title\"})\n",
    "\n",
    "dor_end_date = report_path.stem.split(\" - \")[-2]\n",
    "dor_end_date = (\n",
    "    pd.to_datetime(dor_end_date, format=\"%m%y\", errors=\"raise\")\n",
    "    .to_period(\"M\")\n",
    "    .to_timestamp(\"M\")\n",
    "    .date()\n",
    ")\n",
    "\n",
    "print(dor_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2211a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda s: \"\".join(s.split()).lower() if isinstance(s, str) else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb623b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Unnamed: 0 only if it exists\n",
    "# if \"Unnamed: 0\" in dor.columns:\n",
    "#     dor = dor.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# # desired columns (use canonical names)\n",
    "# desired_cols = [\n",
    "#     \"Project ID\",\n",
    "#     \"DOR Project Title\",\n",
    "#     \"Program Area\",\n",
    "#     \"Funder Type\",\n",
    "#     \"Principal Investigator (PI)\",\n",
    "#     \"Award Term Start Date\",\n",
    "#     \"Project Status\",\n",
    "#     \"Total Cash Receipts\",\n",
    "#     \"Total Personnel\",\n",
    "#     \"Total Contractual/ Outside Services Costs\",\n",
    "#     \"Total Non-Personnel\",\n",
    "#     \"Total Cost\",\n",
    "# ]\n",
    "\n",
    "# # normalize helper to match columns ignoring whitespace/newlines/case\n",
    "# normalize = lambda s: \"\".join(s.split()).lower() if isinstance(s, str) else s\n",
    "# col_map = {normalize(c): c for c in dor.columns}\n",
    "\n",
    "# # build selected column list from available columns (skip missing ones)\n",
    "# selected = []\n",
    "# missing = []\n",
    "# for c in desired_cols:\n",
    "#     key = normalize(c)\n",
    "#     if key in col_map:\n",
    "#         selected.append(col_map[key])\n",
    "#     else:\n",
    "#         missing.append(c)\n",
    "\n",
    "# if missing:\n",
    "#     print(\n",
    "#         f\"Warning: these desired columns were not found and will be skipped: {missing}\"\n",
    "#     )\n",
    "\n",
    "# # subset dataframe to the selected (available) columns\n",
    "# dor = dor[selected]\n",
    "\n",
    "# print(dor.dtypes)\n",
    "\n",
    "dor.to_excel(\n",
    "    \"C:\\\\Users\\\\O304312\\\\OneDrive - Kaiser Permanente\\\\Documents\\\\Tableau Dashboards\\\\New Financial Snapshot\\\\Data\\\\DOR Data Preprocessed.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "txn_base = Path(r\"J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Transaction Detail\")\n",
    "pattern = \"CTP Transaction Detail *.xlsx\"\n",
    "matches = list(txn_base.glob(pattern))\n",
    "\n",
    "if matches:\n",
    "    ctp_path = max(matches, key=lambda p: p.stat().st_mtime)\n",
    "else:\n",
    "\n",
    "    fallback = txn_base / \"CTP Transaction Detail 103125.xlsx\"\n",
    "    if fallback.exists():\n",
    "        ctp_path = fallback\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No files matching {pattern!s} and fallback {fallback!s} not found in {txn_base!s}\"\n",
    "        )\n",
    "\n",
    "ctp_hours = pd.read_excel(ctp_path, sheet_name=\"Hours\", header=[8, 9, 10, 11])\n",
    "\n",
    "\n",
    "def tidy(col):\n",
    "    parts = [\n",
    "        str(x).strip()\n",
    "        for x in col\n",
    "        if str(x).strip() not in {\"nan\", \"\"} and not str(x).startswith(\"Unnamed\")\n",
    "    ]\n",
    "    return \"_\".join(parts).strip(\"_\")\n",
    "\n",
    "\n",
    "ctp_hours.columns = [tidy(col) for col in ctp_hours.columns]\n",
    "\n",
    "ctp_hours = ctp_hours.rename(columns={\"Project\": \"Project ID\"})\n",
    "\n",
    "mask = ctp_hours[\"Project ID\"].astype(str).str.strip().str.lower().str.endswith(\"total\")\n",
    "ctp_hours = ctp_hours[mask].copy()\n",
    "ctp_hours.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rng_mask = (\n",
    "    ctp_hours[\"Project ID\"].astype(str).str.match(r\"^(RNG\\d+)\\s+Total$\", na=False)\n",
    ")\n",
    "ctp_hours.loc[rng_mask, \"Project ID\"] = (\n",
    "    ctp_hours.loc[rng_mask, \"Project ID\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"^(RNG\\d+)\\s+Total$\", r\"\\1\", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "print(\"Columns:\", ctp_hours.columns.tolist())\n",
    "\n",
    "print(\"Loaded dataframe shape:\", ctp_hours.shape)\n",
    "\n",
    "ctp_hours.to_excel(\n",
    "    \"C:\\\\Users\\\\O304312\\\\OneDrive - Kaiser Permanente\\\\Documents\\\\Tableau Dashboards\\\\New Financial Snapshot\\\\Data\\\\DOR Personnel.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb41d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_folder = Path(\"J:\\\\VIEWPOINT\\\\SiteStudyDetails_Response\")\n",
    "\n",
    "pattern = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}-SiteStudyDetails\\.json$\")\n",
    "\n",
    "matches = [p for p in vp_folder.iterdir() if p.is_file() and pattern.match(p.name)]\n",
    "if not matches:\n",
    "    raise FileNotFoundError(f\"No SiteStudyDetails json files found in {vp_folder!s}\")\n",
    "\n",
    "latest_json = max(matches, key=lambda p: p.stat().st_mtime)\n",
    "print(\"Loading:\", latest_json)\n",
    "\n",
    "with latest_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    site_details = json.load(f)\n",
    "\n",
    "try:\n",
    "    ss_df = pd.json_normalize(site_details)\n",
    "    print(\"Converted to DataFrame with shape:\", ss_df.shape)\n",
    "except Exception:\n",
    "    ss_df = None\n",
    "    print(\"JSON loaded into 'site_details' (not converted to DataFrame).\")\n",
    "\n",
    "vp_study_details = ss_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_accountables_folder = Path(\"J:\\\\VIEWPOINT\\\\Accountables_Response\")\n",
    "\n",
    "pattern = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}-Accountables\\.json$\")\n",
    "\n",
    "matches = [\n",
    "    p for p in vp_accountables_folder.iterdir() if p.is_file() and pattern.match(p.name)\n",
    "]\n",
    "if not matches:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No SiteStudyDetails json files found in {vp_accountables_folder!s}\"\n",
    "    )\n",
    "\n",
    "latest_json = max(matches, key=lambda p: p.stat().st_mtime)\n",
    "print(\"Loading:\", latest_json)\n",
    "\n",
    "with latest_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    site_details = json.load(f)\n",
    "\n",
    "try:\n",
    "    account = pd.json_normalize(site_details)\n",
    "    print(\"Converted to DataFrame with shape:\", account.shape)\n",
    "except Exception:\n",
    "    account = None\n",
    "    print(\"JSON loaded into 'site_details' (not converted to DataFrame).\")\n",
    "\n",
    "vp_accountables = account.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_accountables = vp_accountables.merge(\n",
    "    vp_study_details[[\"site_study_service_line\", \"network_study_uuid\"]],\n",
    "    on=\"network_study_uuid\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_accountables[\"completion_date_parsed\"] = pd.to_datetime(\n",
    "    vp_accountables[\"completion_date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "cutoff = pd.to_datetime(dor_end_date)\n",
    "\n",
    "vp_accountables = vp_accountables[\n",
    "    vp_accountables[\"completion_date_parsed\"] < cutoff\n",
    "].copy()\n",
    "\n",
    "vp_accountables.drop(columns=[\"completion_date_parsed\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdfa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_accountables = vp_accountables[\n",
    "    [\"site_study_id\", \"site_study_service_line\", \"amount\"]\n",
    "]\n",
    "vp_accountables = vp_accountables.groupby(\"site_study_service_line\").sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl_re = re.compile(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]\")\n",
    "for col in vp_accountables.select_dtypes(include=[\"object\"]).columns:\n",
    "    mask = vp_accountables[col].notna()\n",
    "    vp_accountables.loc[mask, col] = (\n",
    "        vp_accountables.loc[mask, col].astype(str).map(lambda s: ctl_re.sub(\"\", s))\n",
    "    )\n",
    "\n",
    "vp_accountables.to_excel(\n",
    "    r\"C:\\Users\\O304312\\OneDrive - Kaiser Permanente\\Documents\\Tableau Dashboards\\New Financial Snapshot\\Data\\Viewpoint Accountables.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_study_details.to_excel(\n",
    "    r\"C:\\Users\\O304312\\OneDrive - Kaiser Permanente\\Documents\\Tableau Dashboards\\New Financial Snapshot\\Data\\Viewpoint Site Study Details.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_map = dict(\n",
    "    zip(\n",
    "        vp_accountables[\"site_study_service_line\"],\n",
    "        vp_accountables[\"site_study_service_line\"],\n",
    "    )\n",
    ")\n",
    "vp_set = {\n",
    "    normalize(rng) for rng in vp_accountables[\"site_study_service_line\"].astype(str)\n",
    "}\n",
    "\n",
    "dor[\"Project ID normalized\"] = dor[\"Project ID\"].astype(str).apply(normalize)\n",
    "missing_out = dor[~dor[\"Project ID normalized\"].isin(vp_set)].copy()\n",
    "missing_out = missing_out.drop(columns=[\"Project ID normalized\"])\n",
    "\n",
    "dor_only = missing_out.merge(\n",
    "    dor[[\"Project ID\", \"DOR Project Title\"]], on=\"Project ID\", how=\"left\"\n",
    ")\n",
    "if (\n",
    "    \"DOR Project Title_x\" in dor_only.columns\n",
    "    and \"DOR Project Title_y\" in dor_only.columns\n",
    "):\n",
    "    dor_only[\"DOR Project Title\"] = dor_only[\"DOR Project Title_x\"].combine_first(\n",
    "        dor_only[\"DOR Project Title_y\"]\n",
    "    )\n",
    "    dor_only = dor_only.drop(columns=[\"DOR Project Title_x\", \"DOR Project Title_y\"])\n",
    "\n",
    "dor_only = dor_only[\n",
    "    [\"DOR Project Title\", \"Project ID\"]\n",
    "    + [\n",
    "        col\n",
    "        for col in dor_only.columns\n",
    "        if col not in [\"DOR Project Title\", \"Project ID\"]\n",
    "    ]\n",
    "]\n",
    "\n",
    "dor_only = dor_only[[\"DOR Project Title\", \"Project ID\"]]\n",
    "\n",
    "vp_only_rngs = sorted(\n",
    "    vp_set - {normalize(pid) for pid in dor[\"Project ID\"].astype(str)}\n",
    ")\n",
    "\n",
    "vp_only_site_ids = []\n",
    "for rng in vp_only_rngs:\n",
    "    matching = vp_accountables[\n",
    "        vp_accountables[\"site_study_service_line\"].astype(str).apply(normalize) == rng\n",
    "    ]\n",
    "    if not matching.empty:\n",
    "        vp_only_site_ids.append(matching[\"site_study_id\"].iloc[0])\n",
    "    else:\n",
    "        vp_only_site_ids.append(None)\n",
    "\n",
    "vp_only_df = pd.DataFrame(\n",
    "    {\n",
    "        \"RNG Number\": vp_only_rngs,\n",
    "        \"site_study_id\": [\n",
    "            sid.split(sid.split(\"#\")[1])[0] + \"#\" + sid.split(\"#\")[1] if sid else None\n",
    "            for sid in vp_only_site_ids\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "out_path = r\"C:\\Users\\O304312\\OneDrive - Kaiser Permanente\\Documents\\Tableau Dashboards\\New Financial Snapshot\\Data\\Missing RNG Numbers.xlsx\"\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
    "    dor_only.to_excel(writer, sheet_name=\"DOR Only\", index=False)\n",
    "    vp_only_df.to_excel(writer, sheet_name=\"VP Only\", index=False)\n",
    "\n",
    "print(f\"{len(dor_only)} DOR Project ID(s) not in VP\")\n",
    "print(f\"{len(vp_only_df)} VP RNG number(s) not in DOR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
