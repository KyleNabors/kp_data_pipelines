{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bab7a7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89660aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Monthly Operating Statements\\2025\\Cumulative Report - Operating Statements - 1125 - Hard Coded.xlsx\n",
      "2025-11-30\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base = Path(r\"J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Monthly Operating Statements\")\n",
    "\n",
    "year_dirs = [p for p in base.iterdir() if p.is_dir() and p.name.isdigit()]\n",
    "if not year_dirs:\n",
    "    raise FileNotFoundError(f\"No year folders found under {base!s}\")\n",
    "latest_year_dir = max(year_dirs, key=lambda p: int(p.name))\n",
    "\n",
    "pattern_files = list(\n",
    "    latest_year_dir.glob(\"Cumulative Report - Operating Statements - *.xlsx\")\n",
    ")\n",
    "xlsx_files = pattern_files or list(latest_year_dir.glob(\"*.xlsx\"))\n",
    "if not xlsx_files:\n",
    "    raise FileNotFoundError(f\"No .xlsx files found in {latest_year_dir!s}\")\n",
    "\n",
    "latest_report = max(xlsx_files, key=lambda p: p.stat().st_mtime)\n",
    "\n",
    "report_path = latest_report\n",
    "print(report_path)\n",
    "\n",
    "dor = pd.read_excel(report_path, sheet_name=\"Summary - DC only\", skiprows=6)\n",
    "\n",
    "dor = dor.rename(columns={'Short \"Project\" Title': \"DOR Project Title\"})\n",
    "\n",
    "dor_end_date = report_path.stem.split(\" - \")[-2]\n",
    "\n",
    "dor_end_date = (\n",
    "    pd.to_datetime(dor_end_date, format=\"%m%y\", errors=\"raise\")\n",
    "    .to_period(\"M\")\n",
    "    .to_timestamp(\"M\")\n",
    "    .date()\n",
    ")\n",
    "\n",
    "print(dor_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e8bff5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID                                                               object\n",
      "OL Project Status                                                        object\n",
      "Start Date                                                       datetime64[ns]\n",
      "End Date                                                         datetime64[ns]\n",
      "DOR Project Title                                                        object\n",
      "Principal Investigator                                                   object\n",
      "Funder Type                                                              object\n",
      "Invoice Type                                                             object\n",
      "Total PFSR Direct Budget                                                float64\n",
      "Current Month's\\nDirect Expenses                                          int64\n",
      "Total Direct Expenses                                                   float64\n",
      "Total PFSR Direct Budget \\nvs Total Direct\\nExpenses Variance           float64\n",
      "Total Direct Payments Received                                          float64\n",
      "Total Direct Payments vs. Total Direct Expenses Variance                float64\n",
      "Total Direct and Indirect Payments Received to Date                     float64\n",
      "Total Direct Income/(Loss) based on Invoice Type\\n                      float64\n",
      "Current Month's Payments Received\\n(Incl DAF)                           float64\n",
      "Outstanding Invoices                                                    float64\n",
      "Comments                                                                 object\n",
      "Unnamed: 19                                                             float64\n",
      "Project Area                                                             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dor.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2211a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = lambda s: \"\".join(s.split()).lower() if isinstance(s, str) else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fb623b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Unnamed: 0 only if it exists\n",
    "# if \"Unnamed: 0\" in dor.columns:\n",
    "#     dor = dor.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# # desired columns (use canonical names)\n",
    "# desired_cols = [\n",
    "#     \"Project ID\",\n",
    "#     \"DOR Project Title\",\n",
    "#     \"Program Area\",\n",
    "#     \"Funder Type\",\n",
    "#     \"Principal Investigator (PI)\",\n",
    "#     \"Award Term Start Date\",\n",
    "#     \"Project Status\",\n",
    "#     \"Total Cash Receipts\",\n",
    "#     \"Total Personnel\",\n",
    "#     \"Total Contractual/ Outside Services Costs\",\n",
    "#     \"Total Non-Personnel\",\n",
    "#     \"Total Cost\",\n",
    "# ]\n",
    "\n",
    "# # normalize helper to match columns ignoring whitespace/newlines/case\n",
    "# normalize = lambda s: \"\".join(s.split()).lower() if isinstance(s, str) else s\n",
    "# col_map = {normalize(c): c for c in dor.columns}\n",
    "\n",
    "# # build selected column list from available columns (skip missing ones)\n",
    "# selected = []\n",
    "# missing = []\n",
    "# for c in desired_cols:\n",
    "#     key = normalize(c)\n",
    "#     if key in col_map:\n",
    "#         selected.append(col_map[key])\n",
    "#     else:\n",
    "#         missing.append(c)\n",
    "\n",
    "# if missing:\n",
    "#     print(\n",
    "#         f\"Warning: these desired columns were not found and will be skipped: {missing}\"\n",
    "#     )\n",
    "\n",
    "# # subset dataframe to the selected (available) columns\n",
    "# dor = dor[selected]\n",
    "\n",
    "# print(dor.dtypes)\n",
    "\n",
    "dor.to_excel(\n",
    "    \"C:\\\\Users\\\\O304312\\\\OneDrive - Kaiser Permanente\\\\Documents\\\\Tableau Dashboards\\\\New Financial Snapshot\\\\Data\\\\DOR Data Preprocessed.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df6f625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7afa37c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Transaction Detail\\CTP Transaction Detail 113025.xlsx\n",
      "Columns: ['Project ID', 'NUID', 'Name', '2014', '2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023', '2024', '2025_Qtr1_Jan', '2025_Qtr1_Feb', '2025_Qtr1_Mar', '2025_Qtr2_Apr', '2025_Qtr2_May', '2025_Qtr2_Jun', '2025_Qtr3_Jul', '2025_Qtr3_Aug', '2025_Qtr3_Sep', '2025_Qtr4_Oct', '2025_Qtr4_Nov', '2025 Total', 'Grand Total']\n",
      "Loaded dataframe shape: (213, 27)\n"
     ]
    }
   ],
   "source": [
    "txn_base = Path(r\"J:\\ADMIN-eFILES\\CHEN_W154867_VXC\\z_Reports\\Transaction Detail\")\n",
    "pattern = \"CTP Transaction Detail *.xlsx\"\n",
    "matches = list(txn_base.glob(pattern))\n",
    "\n",
    "if matches:\n",
    "    ctp_path = max(matches, key=lambda p: p.stat().st_mtime)\n",
    "else:\n",
    "\n",
    "    fallback = txn_base / \"CTP Transaction Detail 103125.xlsx\"\n",
    "    if fallback.exists():\n",
    "        ctp_path = fallback\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"No files matching {pattern!s} and fallback {fallback!s} not found in {txn_base!s}\"\n",
    "        )\n",
    "\n",
    "print(\"Loading:\", ctp_path)\n",
    "\n",
    "ctp_hours = pd.read_excel(ctp_path, sheet_name=\"Hours\", header=[8, 9, 10, 11])\n",
    "\n",
    "\n",
    "def tidy(col):\n",
    "    parts = [\n",
    "        str(x).strip()\n",
    "        for x in col\n",
    "        if str(x).strip() not in {\"nan\", \"\"} and not str(x).startswith(\"Unnamed\")\n",
    "    ]\n",
    "    return \"_\".join(parts).strip(\"_\")\n",
    "\n",
    "\n",
    "ctp_hours.columns = [tidy(col) for col in ctp_hours.columns]\n",
    "\n",
    "ctp_hours = ctp_hours.rename(columns={\"Project\": \"Project ID\"})\n",
    "\n",
    "mask = ctp_hours[\"Project ID\"].astype(str).str.strip().str.lower().str.endswith(\"total\")\n",
    "ctp_hours = ctp_hours[mask].copy()\n",
    "ctp_hours.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rng_mask = (\n",
    "    ctp_hours[\"Project ID\"].astype(str).str.match(r\"^(RNG\\d+)\\s+Total$\", na=False)\n",
    ")\n",
    "ctp_hours.loc[rng_mask, \"Project ID\"] = (\n",
    "    ctp_hours.loc[rng_mask, \"Project ID\"]\n",
    "    .astype(str)\n",
    "    .str.replace(r\"^(RNG\\d+)\\s+Total$\", r\"\\1\", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Columns:\", ctp_hours.columns.tolist())\n",
    "\n",
    "print(\"Loaded dataframe shape:\", ctp_hours.shape)\n",
    "\n",
    "ctp_hours.to_excel(\n",
    "    \"C:\\\\Users\\\\O304312\\\\OneDrive - Kaiser Permanente\\\\Documents\\\\Tableau Dashboards\\\\New Financial Snapshot\\\\Data\\\\DOR Personnel.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb41d445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: J:\\VIEWPOINT\\SiteStudyDetails_Response\\2025-12-08-SiteStudyDetails.json\n",
      "Converted to DataFrame with shape: (1078, 40)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "vp_folder = Path(\"J:\\\\VIEWPOINT\\\\SiteStudyDetails_Response\")\n",
    "\n",
    "pattern = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}-SiteStudyDetails\\.json$\")\n",
    "\n",
    "matches = [p for p in vp_folder.iterdir() if p.is_file() and pattern.match(p.name)]\n",
    "if not matches:\n",
    "    raise FileNotFoundError(f\"No SiteStudyDetails json files found in {vp_folder!s}\")\n",
    "\n",
    "latest_json = max(matches, key=lambda p: p.stat().st_mtime)\n",
    "print(\"Loading:\", latest_json)\n",
    "\n",
    "with latest_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    site_details = json.load(f)\n",
    "\n",
    "try:\n",
    "    ss_df = pd.json_normalize(site_details)\n",
    "    print(\"Converted to DataFrame with shape:\", ss_df.shape)\n",
    "except Exception:\n",
    "    ss_df = None\n",
    "    print(\"JSON loaded into 'site_details' (not converted to DataFrame).\")\n",
    "\n",
    "vp_study_details = ss_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f49f7e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: J:\\VIEWPOINT\\Accountables_Response\\2025-12-08-Accountables.json\n",
      "Converted to DataFrame with shape: (12161, 38)\n"
     ]
    }
   ],
   "source": [
    "vp_accountables_folder = Path(\"J:\\\\VIEWPOINT\\\\Accountables_Response\")\n",
    "\n",
    "pattern = re.compile(r\"^\\d{4}-\\d{2}-\\d{2}-Accountables\\.json$\")\n",
    "\n",
    "matches = [\n",
    "    p for p in vp_accountables_folder.iterdir() if p.is_file() and pattern.match(p.name)\n",
    "]\n",
    "if not matches:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No SiteStudyDetails json files found in {vp_accountables_folder!s}\"\n",
    "    )\n",
    "\n",
    "latest_json = max(matches, key=lambda p: p.stat().st_mtime)\n",
    "print(\"Loading:\", latest_json)\n",
    "\n",
    "with latest_json.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    site_details = json.load(f)\n",
    "\n",
    "try:\n",
    "    account = pd.json_normalize(site_details)\n",
    "    print(\"Converted to DataFrame with shape:\", account.shape)\n",
    "except Exception:\n",
    "    account = None\n",
    "    print(\"JSON loaded into 'site_details' (not converted to DataFrame).\")\n",
    "\n",
    "vp_accountables = account.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b0ab9e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_accountables = vp_accountables.merge(\n",
    "    vp_study_details[[\"site_study_service_line\", \"network_study_uuid\"]],\n",
    "    on=\"network_study_uuid\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c8e007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse completion_date safely and compare against a Timestamp cutoff\n",
    "vp_accountables[\"completion_date_parsed\"] = pd.to_datetime(\n",
    "    vp_accountables[\"completion_date\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# ensure dor_end_date is a pandas Timestamp (not a python date)\n",
    "cutoff = pd.to_datetime(dor_end_date)\n",
    "\n",
    "vp_accountables = vp_accountables[\n",
    "    vp_accountables[\"completion_date_parsed\"] < cutoff\n",
    "].copy()\n",
    "\n",
    "# remove helper column\n",
    "vp_accountables.drop(columns=[\"completion_date_parsed\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdfa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_accountables = vp_accountables[\n",
    "    [\"site_study_id\", \"site_study_service_line\", \"amount\"]\n",
    "]\n",
    "vp_accountables = vp_accountables.groupby(\"site_study_service_line\").sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70dc039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove control characters that cause openpyxl IllegalCharacterError\n",
    "# keep common whitespace (\\t, \\n, \\r); remove other < 0x20 controls\n",
    "ctl_re = re.compile(r\"[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]\")\n",
    "for col in vp_accountables.select_dtypes(include=[\"object\"]).columns:\n",
    "    mask = vp_accountables[col].notna()\n",
    "    vp_accountables.loc[mask, col] = (\n",
    "        vp_accountables.loc[mask, col].astype(str).map(lambda s: ctl_re.sub(\"\", s))\n",
    "    )\n",
    "\n",
    "vp_accountables.to_excel(\n",
    "    r\"C:\\Users\\O304312\\OneDrive - Kaiser Permanente\\Documents\\Tableau Dashboards\\New Financial Snapshot\\Data\\Viewpoint Accountables.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc93d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vp_study_details.to_excel(\n",
    "    r\"C:\\Users\\O304312\\OneDrive - Kaiser Permanente\\Documents\\Tableau Dashboards\\New Financial Snapshot\\Data\\Viewpoint Site Study Details.xlsx\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c219e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 DOR Project ID(s) not in VP\n",
      "3 VP RNG number(s) not in DOR\n"
     ]
    }
   ],
   "source": [
    "# Build mapping from VP accountables to extract RNG numbers\n",
    "vp_map = dict(\n",
    "    zip(\n",
    "        vp_accountables[\"site_study_service_line\"],\n",
    "        vp_accountables[\"site_study_service_line\"],\n",
    "    )\n",
    ")\n",
    "vp_set = {\n",
    "    normalize(rng) for rng in vp_accountables[\"site_study_service_line\"].astype(str)\n",
    "}\n",
    "\n",
    "# Find Project IDs in DOR that are not in VP (missing_out)\n",
    "dor[\"Project ID normalized\"] = dor[\"Project ID\"].astype(str).apply(normalize)\n",
    "missing_out = dor[~dor[\"Project ID normalized\"].isin(vp_set)].copy()\n",
    "missing_out = missing_out.drop(columns=[\"Project ID normalized\"])\n",
    "\n",
    "# Merge dor data to get Short \"Project\" Title for missing_out\n",
    "dor_only = missing_out.merge(\n",
    "    dor[[\"Project ID\", \"DOR Project Title\"]], on=\"Project ID\", how=\"left\"\n",
    ")\n",
    "if (\n",
    "    \"DOR Project Title_x\" in dor_only.columns\n",
    "    and \"DOR Project Title_y\" in dor_only.columns\n",
    "):\n",
    "    dor_only[\"DOR Project Title\"] = dor_only[\"DOR Project Title_x\"].combine_first(\n",
    "        dor_only[\"DOR Project Title_y\"]\n",
    "    )\n",
    "    dor_only = dor_only.drop(columns=[\"DOR Project Title_x\", \"DOR Project Title_y\"])\n",
    "\n",
    "# Reorder columns to put DOR Project Title near the front if desired\n",
    "dor_only = dor_only[\n",
    "    [\"DOR Project Title\", \"Project ID\"]\n",
    "    + [\n",
    "        col\n",
    "        for col in dor_only.columns\n",
    "        if col not in [\"DOR Project Title\", \"Project ID\"]\n",
    "    ]\n",
    "]\n",
    "\n",
    "dor_only = dor_only[[\"DOR Project Title\", \"Project ID\"]]\n",
    "# Sheet 2: VP only (RNG numbers in VP but not in DOR)\n",
    "vp_only_rngs = sorted(\n",
    "    vp_set - {normalize(pid) for pid in dor[\"Project ID\"].astype(str)}\n",
    ")\n",
    "\n",
    "# Get site_study_ids for RNG numbers in VP but not in DOR\n",
    "vp_only_site_ids = []\n",
    "for rng in vp_only_rngs:\n",
    "    matching = vp_accountables[\n",
    "        vp_accountables[\"site_study_service_line\"].astype(str).apply(normalize) == rng\n",
    "    ]\n",
    "    if not matching.empty:\n",
    "        vp_only_site_ids.append(matching[\"site_study_id\"].iloc[0])\n",
    "    else:\n",
    "        vp_only_site_ids.append(None)\n",
    "\n",
    "vp_only_df = pd.DataFrame(\n",
    "    {\n",
    "        \"RNG Number\": vp_only_rngs,\n",
    "        \"site_study_id\": [\n",
    "            sid.split(sid.split(\"#\")[1])[0] + \"#\" + sid.split(\"#\")[1] if sid else None\n",
    "            for sid in vp_only_site_ids\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Write both sheets to the same Excel file\n",
    "out_path = r\"C:\\Users\\O304312\\OneDrive - Kaiser Permanente\\Documents\\Tableau Dashboards\\New Financial Snapshot\\Data\\Missing RNG Numbers.xlsx\"\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as writer:\n",
    "    dor_only.to_excel(writer, sheet_name=\"DOR Only\", index=False)\n",
    "    vp_only_df.to_excel(writer, sheet_name=\"VP Only\", index=False)\n",
    "\n",
    "print(f\"{len(dor_only)} DOR Project ID(s) not in VP\")\n",
    "print(f\"{len(vp_only_df)} VP RNG number(s) not in DOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcfe1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
